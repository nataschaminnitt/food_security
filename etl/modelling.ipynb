{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cfec93",
   "metadata": {},
   "source": [
    "# Ethiopia Food Prices – Modelling & Model Comparison\n",
    "\n",
    "## Summary – Ethiopia food price forecasting experiments (Naive vs ARIMA/XGB)\n",
    "\n",
    "**Goal**\n",
    "\n",
    "Explore different time series models for Ethiopia food prices and decide which one to use as the **operational model** for a ~3-month planning horizon, with model tracking in MLflow.\n",
    "\n",
    "---\n",
    "\n",
    "### Data & setup\n",
    "\n",
    "- Data: Ethiopia Tier A panel (`ethiopia_foodprices_model_panel_tierA.parquet`), monthly prices.\n",
    "- Series unit: `(admin_1, product)` pairs.\n",
    "- Main target: `value_imputed` → renamed to `y` for modelling.\n",
    "- Two main data “views”:\n",
    "  - **StatsForecast panel:** `unique_id` (admin_1 · product), `ds` (month-end), `y`.\n",
    "  - **Feature-based panel:** built via `staples_model_core.py`:\n",
    "    - `impute_features` → handle rain/FAO/ptm/population, missingness flags.\n",
    "    - `build_features` → lags (`y_lag1,3,6,12`), rolling stats, month number, seasonal encodings (`mo_sin`, `mo_cos`).\n",
    "    - `encode_ids`, `pick_features`, `time_split` for train/test.\n",
    "\n",
    "---\n",
    "\n",
    "### Models evaluated\n",
    "\n",
    "**1. StatsForecast baselines (panel models)**  \n",
    "Trained on per-series history in `df_sf`:\n",
    "\n",
    "- `sf_Naive`: random walk (forecast = last observed y).\n",
    "- `sf_WindowAverage(12)` (earlier) – simple 12-month moving average.\n",
    "- `sf_ARIMA`: `AutoARIMA(seasonal=False, alias=\"ARIMA\")`.\n",
    "- `sf_SARIMA`: `AutoARIMA(season_length=12, alias=\"SARIMA\")`.\n",
    "- `sf_NaiveDrift`: custom “Naive + drift” model:\n",
    "  - Per series, compute average recent monthly change (last 6 diffs).\n",
    "  - Forecast: `y_t + h * drift`.\n",
    "\n",
    "**2. Global feature-based model (XGBoost)**\n",
    "\n",
    "- Common engineered feature set from `staples_model_core.py`:\n",
    "  - Lags, rolling stats, month encodings, rain/FAO/PTM/population, etc.\n",
    "- Global XGBoost regressor (one model across all series):\n",
    "  - Hyperparameters tuned with Optuna on sMAPE (log-space target).\n",
    "  - `fit_xgb_compat` handles early stopping on the tail of the training period.\n",
    "\n",
    "**3. Hybrid residual-corrected model**\n",
    "\n",
    "- Base: global XGB prediction `y_pred_global` (in level).\n",
    "- Residuals: `resid = y - y_pred_global`.\n",
    "- For each **product**, fit a small Ridge regression on the residuals:\n",
    "  - Features: `[y_pred_global]` only.\n",
    "  - `residual_corrector(product)`.\n",
    "- Final forecast:  \n",
    "  `y_pred_hybrid = y_pred_global + correction(product, y_pred_global)`.\n",
    "\n",
    "Later, this logic was generalized into a `GroupResidualCorrector` class that can, in principle, correct any base model per product or per (admin_1, product). In practice, the hybrid did **not** beat Naive / SARIMA for this dataset and horizon.\n",
    "\n",
    "---\n",
    "\n",
    "### Horizons tested\n",
    "\n",
    "Two horizons were explicitly compared using StatsForecast models:\n",
    "\n",
    "- **h = 3 months** (`h3`) – the main planning horizon.\n",
    "- **h = 6 months** (`h6`) – to check if longer-horizon behaviour changes which model is best.\n",
    "\n",
    "For each horizon, the last `h` months per series were used as test; the rest as train.\n",
    "\n",
    "---\n",
    "\n",
    "### Key results\n",
    "\n",
    "#### Horizon h = 3 (short-term, operational horizon)\n",
    "\n",
    "Panel-level metrics (approximate):\n",
    "\n",
    "- **sf_Naive_h3**  \n",
    "  - MAE ≈ **5.79**  \n",
    "  - RMSE ≈ **8.66**  \n",
    "  - sMAPE ≈ **6.03%**  ← **Best model**\n",
    "- **sf_SARIMA_h3**  \n",
    "  - MAE ≈ 7.07, RMSE ≈ 9.94, sMAPE ≈ 7.30%\n",
    "- **sf_ARIMA_h3**  \n",
    "  - MAE ≈ 7.94, RMSE ≈ 12.17, sMAPE ≈ 7.67%\n",
    "- **sf_NaiveDrift_h3**  \n",
    "  - MAE ≈ 8.82, RMSE ≈ 14.47, sMAPE ≈ 7.68%\n",
    "\n",
    "- Global XGB and hybrid XGB were **worse** than Naive on all metrics.\n",
    "- Naive+Drift also performed **worse** than plain Naive.\n",
    "\n",
    "**Conclusion for h=3:**  \n",
    "For extremely volatile Ethiopian food prices with only strong lag-1 autocorrelation, a simple **Naive (last-value) model** is the most accurate and robust. Extra structure (ARIMA, SARIMA, XGB, drift) does **not** improve short-horizon forecasts.\n",
    "\n",
    "#### Horizon h = 6 (longer horizon check)\n",
    "\n",
    "- **sf_Naive_h6**: MAE ≈ 11.90, RMSE ≈ 18.87, sMAPE ≈ 10.51%\n",
    "- **sf_ARIMA_h6**: MAE ≈ **11.01**, RMSE ≈ 16.92, sMAPE ≈ 10.55%\n",
    "- **sf_SARIMA_h6**: MAE ≈ 11.29, RMSE ≈ **16.73**, sMAPE ≈ 10.94%\n",
    "- **sf_NaiveDrift_h6**: clearly worse than all others.\n",
    "\n",
    "**Conclusion for h=6:**  \n",
    "At 6 months, **ARIMA/SARIMA slightly outperform Naive** on MAE/RMSE, suggesting some weak medium-term structure, but gains are modest.\n",
    "\n",
    "---\n",
    "\n",
    "### Final decision for the dashboard\n",
    "\n",
    "Given the planning need is **3 months ahead**, and Ethiopian prices are highly volatile:\n",
    "\n",
    "- **Chosen production model:** `sf_Naive_h3`  \n",
    "  → Forecast for each `(admin_1, product, month+h)` = **last observed price** for that series.\n",
    "\n",
    "- Feature-based XGB + hybrid and ARIMA/SARIMA remain:\n",
    "  - Logged in MLflow for tracking and future experiments.\n",
    "  - Potentially useful later for:\n",
    "    - longer horizons,\n",
    "    - richer exogenous data,\n",
    "    - scenario / sensitivity analysis.\n",
    "\n",
    "For now, the dashboard’s operational forecast adopts the **Naive model with horizon = 3 months**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57614915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 1. Imports & basic setup =========================\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/nataschajademinnitt/Documents/5_data/food_security/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Time-series packages\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive, WindowAverage, AutoARIMA\n",
    "from utilsforecast.losses import mae, mape, rmse, smape\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "# ML & feature-based modelling\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "\n",
    "# Your custom ETL / modelling utilities\n",
    "from etl.staples_model_core import (\n",
    "    impute_features,\n",
    "    build_features,\n",
    "    encode_ids,\n",
    "    pick_features,\n",
    "    time_split,\n",
    "    tune_xgb,\n",
    "    fit_xgb_compat,\n",
    "    smape as smape_vec,\n",
    "    rmse as rmse_vec,\n",
    "    TEST_HORIZON_MONTHS,\n",
    "    N_TRIALS,\n",
    "    SEED,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "mlflow.set_experiment(\"ethiopia_food_prices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 2. Helper functions & classes =========================\n",
    "\n",
    "from typing import List, Optional, Union, Dict, Tuple\n",
    "\n",
    "\n",
    "def compute_panel_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Flat MAE, RMSE, sMAPE over all series & horizons.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    if len(y_true) == 0:\n",
    "        return {\"mae\": np.nan, \"rmse\": np.nan, \"smape\": np.nan}\n",
    "\n",
    "    mae_val = mean_absolute_error(y_true, y_pred)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred) + 1e-9) / 2.0\n",
    "    smape_val = np.mean(np.abs(y_pred - y_true) / denom) * 100.0\n",
    "\n",
    "    return {\"mae\": mae_val, \"rmse\": rmse_val, \"smape\": smape_val}\n",
    "\n",
    "\n",
    "def log_run_to_mlflow(model_name, metrics, params=None, tags=None):\n",
    "    \"\"\"\n",
    "    Helper to log a single model run in MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        if tags:\n",
    "            mlflow.set_tags(tags)\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "\n",
    "class GroupResidualCorrector:\n",
    "    \"\"\"\n",
    "    Generic group-wise residual corrector.\n",
    "\n",
    "    - You give it:\n",
    "        * group_cols: columns defining a time series group (e.g. [\"product\"] or [\"admin_1\", \"product\"])\n",
    "        * main_pred_col: name of the base model prediction column (used to define residuals)\n",
    "        * feature_cols: columns used as features for residual model (defaults to [main_pred_col])\n",
    "        * target_col: name of true target column\n",
    "    - It fits a small regression model per group to predict residuals:\n",
    "        residual = y_true - y_pred_main\n",
    "    - At prediction time, it adds:\n",
    "        corrected = y_pred_main + predicted_residual\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        group_cols: Union[str, List[str]],\n",
    "        main_pred_col: str,\n",
    "        feature_cols: Optional[List[str]] = None,\n",
    "        target_col: str = \"y\",\n",
    "        min_n: int = 12,\n",
    "        base_estimator_factory=None,\n",
    "    ):\n",
    "        self.group_cols = [group_cols] if isinstance(group_cols, str) else list(group_cols)\n",
    "        self.main_pred_col = main_pred_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "        self.min_n = min_n\n",
    "\n",
    "        if base_estimator_factory is None:\n",
    "            def default_factory():\n",
    "                return Pipeline([\n",
    "                    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "                    (\"ridge\", Ridge(alpha=2.0, fit_intercept=True, random_state=SEED)),\n",
    "                ])\n",
    "            self.base_estimator_factory = default_factory\n",
    "        else:\n",
    "            self.base_estimator_factory = base_estimator_factory\n",
    "\n",
    "        self.models_: Dict[Tuple, Pipeline] = {}\n",
    "\n",
    "    def fit(self, df: pd.DataFrame) -> \"GroupResidualCorrector\":\n",
    "        if self.feature_cols is None:\n",
    "            self.feature_cols = [self.main_pred_col]\n",
    "\n",
    "        required = set(self.group_cols + [self.target_col, self.main_pred_col] + self.feature_cols)\n",
    "        missing = required - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"DataFrame is missing required columns: {missing}\")\n",
    "\n",
    "        self.models_.clear()\n",
    "\n",
    "        for g_key, sub in df.groupby(self.group_cols, observed=False):\n",
    "            if len(sub) < self.min_n:\n",
    "                continue\n",
    "\n",
    "            y_true = sub[self.target_col].to_numpy(dtype=float)\n",
    "            y_base = sub[self.main_pred_col].to_numpy(dtype=float)\n",
    "            residuals = y_true - y_base\n",
    "\n",
    "            X = sub[self.feature_cols].to_numpy(dtype=float)\n",
    "            model = self.base_estimator_factory()\n",
    "            model.fit(X, residuals)\n",
    "            self.models_[g_key] = model\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        new_col: str = \"y_pred_corrected\",\n",
    "        inplace: bool = False,\n",
    "    ) -> pd.DataFrame:\n",
    "        if not self.models_:\n",
    "            raise RuntimeError(\"You must call .fit() before .predict().\")\n",
    "\n",
    "        if self.feature_cols is None:\n",
    "            self.feature_cols = [self.main_pred_col]\n",
    "\n",
    "        required = set(self.group_cols + [self.main_pred_col] + self.feature_cols)\n",
    "        missing = required - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"DataFrame is missing required columns: {missing}\")\n",
    "\n",
    "        out = df if inplace else df.copy()\n",
    "        out[new_col] = out[self.main_pred_col].astype(float)\n",
    "\n",
    "        for g_key, sub_idx in out.groupby(self.group_cols, observed=False).groups.items():\n",
    "            model = self.models_.get(g_key)\n",
    "            if model is None:\n",
    "                continue\n",
    "            X = out.loc[sub_idx, self.feature_cols].to_numpy(dtype=float)\n",
    "            corr = model.predict(X)\n",
    "            base_vals = out.loc[sub_idx, self.main_pred_col].to_numpy(dtype=float)\n",
    "            out.loc[sub_idx, new_col] = base_vals + corr\n",
    "\n",
    "        return out\n",
    "    \n",
    "def forecast_naive_drift(train_sf, test_sf, h, drift_window=6, col_name=\"NaiveDrift\"):\n",
    "    \"\"\"\n",
    "    Naive + drift model:\n",
    "      - per unique_id, fit a constant drift = mean of last `drift_window` diffs\n",
    "      - forecast h steps ahead: y_t + k * drift, k=1..h\n",
    "    Returns a DataFrame with columns ['unique_id', 'ds', col_name].\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "\n",
    "    for uid, g_train in train_sf.groupby(\"unique_id\", observed=False):\n",
    "        g_train = g_train.sort_values(\"ds\")\n",
    "        g_test = (\n",
    "            test_sf.loc[test_sf[\"unique_id\"] == uid]\n",
    "                   .sort_values(\"ds\")\n",
    "        )\n",
    "        if g_test.empty:\n",
    "            continue\n",
    "\n",
    "        y_train = g_train[\"y\"].to_numpy()\n",
    "        last_y = y_train[-1]\n",
    "\n",
    "        diffs = np.diff(y_train)\n",
    "        if len(diffs) == 0:\n",
    "            drift = 0.0\n",
    "        else:\n",
    "            drift = diffs[-drift_window:].mean()\n",
    "\n",
    "        horizon = len(g_test)\n",
    "        y_forecast = [last_y + (i + 1) * drift for i in range(horizon)]\n",
    "\n",
    "        tmp = g_test[[\"unique_id\", \"ds\"]].copy()\n",
    "        tmp[col_name] = y_forecast\n",
    "        preds.append(tmp)\n",
    "\n",
    "    if not preds:\n",
    "        return pd.DataFrame(columns=[\"unique_id\", \"ds\", col_name])\n",
    "\n",
    "    return pd.concat(preds, ignore_index=True)\n",
    "\n",
    "def make_train_test_statsforecast(df_sf, horizon):\n",
    "    counts = df_sf.groupby(\"unique_id\")[\"ds\"].count()\n",
    "    ok_ids = counts[counts > horizon].index\n",
    "    df_sub = df_sf[df_sf[\"unique_id\"].isin(ok_ids)].reset_index(drop=True)\n",
    "\n",
    "    test = df_sub.groupby(\"unique_id\", group_keys=False).tail(horizon).reset_index(drop=True)\n",
    "    train = (\n",
    "        df_sub.groupby(\"unique_id\", group_keys=False)\n",
    "              .apply(lambda g: g.iloc[:-horizon])\n",
    "              .reset_index(drop=True)\n",
    "    )\n",
    "    return train, test\n",
    "\n",
    "def run_sf_models_for_horizon(df_sf_train, df_sf_test, horizon, label_suffix):\n",
    "    models_sf = [\n",
    "        Naive(),\n",
    "        AutoARIMA(seasonal=False, alias='ARIMA'),\n",
    "        AutoARIMA(season_length=12, alias='SARIMA'),\n",
    "    ]\n",
    "\n",
    "    sf = StatsForecast(models=models_sf, freq=\"M\", n_jobs=-1)\n",
    "    sf.fit(df=df_sf_train)\n",
    "\n",
    "    preds = sf.predict(h=horizon)\n",
    "    eval_df = df_sf_test.merge(preds, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "\n",
    "    model_cols = [c for c in eval_df.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "    rows = []\n",
    "    for col in model_cols:\n",
    "        model_name = f\"sf_{col}_{label_suffix}\"\n",
    "        metrics = compute_panel_metrics(eval_df[\"y\"], eval_df[col])\n",
    "        print(model_name, metrics)\n",
    "        rows.append({\"model\": model_name, **metrics})\n",
    "\n",
    "        log_run_to_mlflow(\n",
    "            model_name=model_name,\n",
    "            metrics=metrics,\n",
    "            params={\"family\": \"statsforecast\", \"horizon\": horizon},\n",
    "            tags={\"kind\": f\"baseline_{label_suffix}\"}\n",
    "        )\n",
    "\n",
    "    # Naive+drift for this horizon\n",
    "    nd_preds = forecast_naive_drift(df_sf_train, df_sf_test, h=horizon,\n",
    "                                    drift_window=6, col_name=\"NaiveDrift\")\n",
    "    eval_nd = df_sf_test.merge(nd_preds, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "    metrics_nd = compute_panel_metrics(eval_nd[\"y\"], eval_nd[\"NaiveDrift\"])\n",
    "\n",
    "    nd_name = f\"sf_NaiveDrift_{label_suffix}\"\n",
    "    print(nd_name, metrics_nd)\n",
    "    rows.append({\"model\": nd_name, **metrics_nd})\n",
    "    log_run_to_mlflow(\n",
    "        model_name=nd_name,\n",
    "        metrics=metrics_nd,\n",
    "        params={\"family\": \"naive_drift\", \"horizon\": horizon, \"drift_window\": 6},\n",
    "        tags={\"kind\": f\"baseline_plus_{label_suffix}\"}\n",
    "    )\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30379e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 3. Load data & build panels =========================\n",
    "\n",
    "PARQUET_PATH = \"data/processed/ethiopia_foodprices_model_panel_tierA.parquet\"\n",
    "panel = pd.read_parquet(PARQUET_PATH)\n",
    "\n",
    "print(\"Top-level columns:\", list(panel.columns))\n",
    "\n",
    "# --- A) StatsForecast panel (unique_id, ds, y) ---\n",
    "\n",
    "H = TEST_HORIZON_MONTHS  # test/forecast horizon in months\n",
    "\n",
    "df_sf = (\n",
    "    panel.rename(columns={\"month\": \"ds\", \"value_imputed\": \"y\"})\n",
    "          .assign(\n",
    "              ds=lambda d: pd.to_datetime(d[\"ds\"], errors=\"coerce\")\n",
    "                             .dt.to_period(\"M\").dt.to_timestamp(\"M\"),\n",
    "              unique_id=lambda d: d[\"admin_1\"].astype(str) + \" · \" + d[\"product\"].astype(str),\n",
    "          )[[\"unique_id\", \"ds\", \"y\"]]\n",
    "          .groupby([\"unique_id\", \"ds\"], as_index=False)[\"y\"].mean()\n",
    "          .sort_values([\"unique_id\", \"ds\"])\n",
    ")\n",
    "\n",
    "# Remove series with very short history (need at least H+1 points)\n",
    "counts = df_sf.groupby(\"unique_id\")[\"ds\"].count()\n",
    "ok_ids = counts[counts > H].index\n",
    "df_sf = df_sf[df_sf[\"unique_id\"].isin(ok_ids)].reset_index(drop=True)\n",
    "\n",
    "test_sf = df_sf.groupby(\"unique_id\", group_keys=False).tail(H).reset_index(drop=True)\n",
    "train_sf = (\n",
    "    df_sf.groupby(\"unique_id\", group_keys=False)\n",
    "         .apply(lambda g: g.iloc[:-H])\n",
    "         .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"StatsForecast panel:\", df_sf.shape, \"train:\", train_sf.shape, \"test:\", test_sf.shape)\n",
    "\n",
    "\n",
    "# --- B) Feature-based panel for global XGB (your existing pipeline) ---\n",
    "\n",
    "# Feature engineering\n",
    "staples = impute_features(panel)\n",
    "df_feat = build_features(staples)\n",
    "df_feat = encode_ids(df_feat)\n",
    "df_feat = df_feat.sort_values([\"month\", \"admin_1\", \"product\"]).reset_index(drop=True)\n",
    "\n",
    "feats = pick_features(df_feat)\n",
    "df_feat[feats] = df_feat[feats].apply(pd.to_numeric, errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "# Split into train/test (time-based)\n",
    "train_df, test_df = time_split(df_feat, horizon=TEST_HORIZON_MONTHS)\n",
    "\n",
    "X_train, X_test = train_df[feats], test_df[feats]\n",
    "y_train_log = np.log1p(train_df[\"y\"])\n",
    "y_test_true = test_df[\"y\"].to_numpy()\n",
    "\n",
    "print(\"Feature-based panel train/test:\", train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09814cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 4. StatsForecast baselines =========================\n",
    "\n",
    "results = []   # will collect summary metrics for all models\n",
    "\n",
    "models_sf = [\n",
    "    Naive(),\n",
    "    WindowAverage(window_size=12),\n",
    "    AutoARIMA(seasonal=False, alias='ARIMA'),\n",
    "    AutoARIMA(season_length=12, alias='SARIMA'),\n",
    "]\n",
    "\n",
    "sf = StatsForecast(models=models_sf, freq=\"M\", n_jobs=-1)\n",
    "sf.fit(df=train_sf)\n",
    "\n",
    "preds_sf = sf.predict(h=H)  # columns: unique_id, ds, <model cols>\n",
    "eval_sf = test_sf.merge(preds_sf, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "\n",
    "model_cols = [c for c in eval_sf.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "for col in model_cols:\n",
    "    model_name = f\"sf_{col}\"\n",
    "    y_true = eval_sf[\"y\"].values\n",
    "    y_pred = eval_sf[col].values\n",
    "\n",
    "    metrics = compute_panel_metrics(y_true, y_pred)\n",
    "    results.append({\"model\": model_name, **metrics})\n",
    "\n",
    "    log_run_to_mlflow(\n",
    "        model_name=model_name,\n",
    "        metrics=metrics,\n",
    "        params={\"family\": \"statsforecast\", \"horizon\": H},\n",
    "        tags={\"kind\": \"baseline\"}\n",
    "    )\n",
    "\n",
    "# --- Naive + drift model on the same horizon H ---\n",
    "\n",
    "nd_preds = forecast_naive_drift(train_sf, test_sf, h=H, drift_window=6, col_name=\"NaiveDrift\")\n",
    "eval_nd = test_sf.merge(nd_preds, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "\n",
    "metrics_nd = compute_panel_metrics(eval_nd[\"y\"], eval_nd[\"NaiveDrift\"])\n",
    "print(\"Naive+drift metrics:\", metrics_nd)\n",
    "\n",
    "results.append({\"model\": \"sf_NaiveDrift\", **metrics_nd})\n",
    "\n",
    "log_run_to_mlflow(\n",
    "    model_name=\"sf_NaiveDrift\",\n",
    "    metrics=metrics_nd,\n",
    "    params={\"family\": \"naive_drift\", \"horizon\": H, \"drift_window\": 6},\n",
    "    tags={\"kind\": \"baseline_plus\"}\n",
    ")\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive, SeasonalNaive, AutoARIMA, WindowAverage\n",
    "from utilsforecast.losses import mae, mape, rmse, smape\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "H_LIST = [3, 6]  # horizons you want to compare\n",
    "\n",
    "def evaluate_statsforecast_models(df_sf, h, n_windows=3):\n",
    "    \"\"\"\n",
    "    Run StatsForecast cross-validation for baseline models at horizon h\n",
    "    and return a tidy metrics DataFrame (one row per model).\n",
    "    \"\"\"\n",
    "    models = [\n",
    "        Naive(),  # last value\n",
    "        SeasonalNaive(season_length=12, alias=\"SeasonalNaive_12\"),\n",
    "        WindowAverage(window_size=3, alias=\"WindowAvg_3\"),\n",
    "        AutoARIMA(seasonal=False, alias=\"ARIMA\"),\n",
    "        AutoARIMA(season_length=12, alias=\"SARIMA\"),\n",
    "    ]\n",
    "    \n",
    "    sf = StatsForecast(models=models, freq=\"M\", n_jobs=-1)\n",
    "    \n",
    "    cv_df = sf.cross_validation(\n",
    "        h=h,\n",
    "        df=df_sf,\n",
    "        n_windows=n_windows,\n",
    "        step_size=h,\n",
    "        refit=True,\n",
    "    )\n",
    "    \n",
    "    # utilsforecast.evaluation.evaluate returns a *wide* table:\n",
    "    # columns: ['unique_id', 'metric', 'Naive', 'SeasonalNaive_12', ...]\n",
    "    cv_eval = evaluate(\n",
    "        cv_df.drop([\"cutoff\"], axis=1),\n",
    "        metrics=[mae, mape, rmse, smape],\n",
    "    )\n",
    "    \n",
    "    # Melt to long: one row per (unique_id, metric, model)\n",
    "    id_vars = [c for c in [\"unique_id\", \"metric\"] if c in cv_eval.columns]\n",
    "    cv_long = cv_eval.melt(\n",
    "        id_vars=id_vars,\n",
    "        var_name=\"model\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    \n",
    "    # Average across series: one row per (model, metric)\n",
    "    out = (\n",
    "        cv_long\n",
    "        .groupby([\"model\", \"metric\"], observed=False)[\"value\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"model\", columns=\"metric\", values=\"value\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    out[\"horizon\"] = h\n",
    "    return out\n",
    "\n",
    "all_results = []\n",
    "for h in H_LIST:\n",
    "    res_h = evaluate_statsforecast_models(df_sf, h=h, n_windows=3)\n",
    "    all_results.append(res_h)\n",
    "\n",
    "sf_results = pd.concat(all_results, ignore_index=True)\n",
    "sf_results = sf_results.set_index([\"model\", \"horizon\"]).sort_index()\n",
    "sf_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 5. StatsForecast Compare Horizons =========================\n",
    "\n",
    "H_SHORT = TEST_HORIZON_MONTHS   \n",
    "H_LONG = 6                      \n",
    "\n",
    "train_sf_short, test_sf_short = make_train_test_statsforecast(df_sf, H_SHORT)\n",
    "train_sf_long,  test_sf_long  = make_train_test_statsforecast(df_sf, H_LONG)\n",
    "\n",
    "print(\"Short horizon:\", train_sf_short.shape, test_sf_short.shape)\n",
    "print(\"Long horizon :\", train_sf_long.shape,  test_sf_long.shape)\n",
    "\n",
    "results = []  # or extend your existing list\n",
    "\n",
    "rows_short = run_sf_models_for_horizon(train_sf_short, test_sf_short, H_SHORT, label_suffix=\"h3\")\n",
    "rows_long  = run_sf_models_for_horizon(train_sf_long,  test_sf_long,  H_LONG,  label_suffix=\"h6\")\n",
    "\n",
    "results.extend(rows_short)\n",
    "results.extend(rows_long)\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .set_index(\"model\")\n",
    "    .sort_values([\"smape\", \"rmse\"])\n",
    ")\n",
    "display(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 6. Global XGBoost model (feature-based) =========================\n",
    "\n",
    "# How many distinct months of history in the training period?\n",
    "hist_month_counts = (\n",
    "    train_df\n",
    "    .groupby([\"admin_1\", \"product\"])[\"month\"]\n",
    "    .nunique()\n",
    "    .rename(\"n_hist_months\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "test_df = test_df.merge(hist_month_counts, on=[\"admin_1\", \"product\"], how=\"left\")\n",
    "test_df[\"has_12m_hist\"] = test_df[\"n_hist_months\"].fillna(0) >= 12\n",
    "\n",
    "print(\"Number of test rows with ≥12 months history:\", test_df[\"has_12m_hist\"].sum())\n",
    "\n",
    "print(f\"Tuning XGB global model ({N_TRIALS} trials)…\")\n",
    "best_params = tune_xgb(X_train, y_train_log, n_trials=N_TRIALS, seed=SEED)\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "# Simple validation split: last 2 months as validation, if available\n",
    "last_train_m = train_df[\"month\"].max()\n",
    "val_cut = (last_train_m.to_period(\"M\") - 2).to_timestamp()\n",
    "\n",
    "val_mask = train_df[\"month\"] >= val_cut\n",
    "X_tr_es, y_tr_es = X_train[~val_mask], y_train_log[~val_mask]\n",
    "X_va_es, y_va_es = X_train[val_mask],  y_train_log[val_mask]\n",
    "\n",
    "if len(X_va_es) == 0:\n",
    "    X_tr_es, y_tr_es = X_train, y_train_log\n",
    "    X_va_es = y_va_es = None\n",
    "\n",
    "final_model = fit_xgb_compat(\n",
    "    best_params,\n",
    "    X_tr_es,\n",
    "    y_tr_es,\n",
    "    X_va_es,\n",
    "    y_va_es,\n",
    "    early_rounds=200,\n",
    ")\n",
    "\n",
    "# Base predictions (in level space)\n",
    "train_df[\"y_pred_xgb\"] = np.expm1(final_model.predict(X_train))\n",
    "test_df[\"y_pred_xgb\"] = np.expm1(final_model.predict(X_test))\n",
    "\n",
    "# Restrict evaluation to rows with adequate history\n",
    "mask_ok = test_df[\"has_12m_hist\"]\n",
    "eval_xgb = test_df[mask_ok].copy()\n",
    "\n",
    "valid_mask_base = eval_xgb[\"y_pred_xgb\"].notna() & eval_xgb[\"y\"].notna()\n",
    "\n",
    "metrics_xgb_base = compute_panel_metrics(\n",
    "    eval_xgb.loc[valid_mask_base, \"y\"],\n",
    "    eval_xgb.loc[valid_mask_base, \"y_pred_xgb\"],\n",
    ")\n",
    "print(\"Global XGB base metrics:\", metrics_xgb_base)\n",
    "\n",
    "results.append({\"model\": \"xgb_global_base\", **metrics_xgb_base})\n",
    "\n",
    "log_run_to_mlflow(\n",
    "    model_name=\"xgb_global_base\",\n",
    "    metrics=metrics_xgb_base,\n",
    "    params={\n",
    "        \"family\": \"global_ml\",\n",
    "        \"horizon\": TEST_HORIZON_MONTHS,\n",
    "        \"n_features\": len(feats),\n",
    "        **{f\"xgb_{k}\": v for k, v in best_params.items()},\n",
    "    },\n",
    "    tags={\"kind\": \"candidate\", \"uses_residual_correction\": False},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 7. Hybrid / residual-corrected XGB =========================\n",
    "\n",
    "# Fit residual correctors per product\n",
    "corrector_xgb = GroupResidualCorrector(\n",
    "    group_cols=\"product\",                 # or [\"admin_1\", \"product\"]\n",
    "    main_pred_col=\"y_pred_xgb\",\n",
    "    feature_cols=[\"y_pred_xgb\"],         # simple correction, can add more features later\n",
    "    target_col=\"y\",\n",
    "    min_n=12,\n",
    ")\n",
    "\n",
    "corrector_xgb.fit(train_df)\n",
    "\n",
    "# Apply to test set (only rows with ≥12m history are evaluated)\n",
    "eval_xgb = corrector_xgb.predict(eval_xgb, new_col=\"y_pred_xgb_hybrid\", inplace=True)\n",
    "\n",
    "valid_mask_hybrid = eval_xgb[\"y_pred_xgb_hybrid\"].notna() & eval_xgb[\"y\"].notna()\n",
    "\n",
    "metrics_xgb_hybrid = compute_panel_metrics(\n",
    "    eval_xgb.loc[valid_mask_hybrid, \"y\"],\n",
    "    eval_xgb.loc[valid_mask_hybrid, \"y_pred_xgb_hybrid\"],\n",
    ")\n",
    "print(\"Global XGB hybrid metrics:\", metrics_xgb_hybrid)\n",
    "\n",
    "results.append({\"model\": \"xgb_global_hybrid\", **metrics_xgb_hybrid})\n",
    "\n",
    "log_run_to_mlflow(\n",
    "    model_name=\"xgb_global_hybrid\",\n",
    "    metrics=metrics_xgb_hybrid,\n",
    "    params={\n",
    "        \"family\": \"global_ml\",\n",
    "        \"horizon\": TEST_HORIZON_MONTHS,\n",
    "        \"n_features\": len(feats),\n",
    "        \"residual_group\": \"product\",\n",
    "        \"residual_features\": \"y_pred_xgb\",\n",
    "        **{f\"xgb_{k}\": v for k, v in best_params.items()},\n",
    "    },\n",
    "    tags={\"kind\": \"production_candidate\", \"uses_residual_correction\": True},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= 8. Final model comparison table =========================\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(results)\n",
    "    .drop_duplicates(subset=[\"model\"])\n",
    "    .set_index(\"model\")\n",
    "    .sort_values(\"smape\")   # smaller is better\n",
    ")\n",
    "\n",
    "print(\"Model ranking (lower is better):\")\n",
    "display(results_df)\n",
    "\n",
    "best_model_name = results_df.index[0]\n",
    "best_model_metrics = results_df.iloc[0].to_dict()\n",
    "\n",
    "print(\"\\nBest model:\", best_model_name)\n",
    "print(\"Metrics:\", best_model_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodsec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
